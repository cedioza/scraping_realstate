# Scraper Orchestrator

Este repositorio contiene un sistema unificado para ejecutar diversos scrapers inmobiliarios (Idealista, Fotocasa, Altamira, Solvia, Aliseda) desde una √∫nica plataforma mediante un panel web y una API REST centralizada.

## üèóÔ∏è Estructura del Proyecto

- `scraper-api/`: Backend en Node.js (Express) que expone los endpoints para lanzar los scrapers.
- `scraper-frontend/`: Frontend moderno en Vanilla JS y CSS que sirve de panel de control (Dashboard).
- `idealista-scraper/`: Crawler para Idealista (usa Crawlee).
- `fotocasa-scraper/`: Crawler para Fotocasa (usa Playwright).
- `altamira-scraper/`, `solvia-scraper/`, `aliseda-scraper/`: Crawlers para las respectivas entidades (usan Crawlee y Playwright).

## üöÄ Requisitos Previos

1. Node.js instalado (v18 recomendada).
2. Tener configurado el archivo `.env` en cada scraper espec√≠fico si requiere variables adicionales (ej. BrightData para Idealista).

## üíª Instrucciones de Ejecuci√≥n

Para iniciar el sistema completo, necesitas ejecutar la API en una terminal y el Frontend en otra.

### 1. Iniciar la API Backend

Abre una terminal, sit√∫ate en la carpeta `scraper-api`, instala dependencias (si es primera vez) y arranca el servidor:

```bash
cd scraper-api
npm install
npm start
```

La API escuchar√° en **http://localhost:3000**
Puedes visitar la **Documentaci√≥n T√©cnica Interactiva** (Swagger) en **http://localhost:3000/api-docs**.

### 2. Iniciar el Frontend (Panel de Control Web)

Abre otra terminal, sit√∫ate en `scraper-frontend`, instala dependencias y arranca Vite:

```bash
cd scraper-frontend
npm install
npm run dev
```

Esto abrir√° un servidor local (t√≠picamente en **http://localhost:5173**). √Åbrelo en tu navegador para ver la interfaz gr√°fica.

## ‚öôÔ∏è Uso del Sistema

1. **Desde el Panel Web (Frontend):**
   - Entra a `http://localhost:5173`.
   - Selecciona el portal que deseas scrapear.
   - Pega la URL objetivo.
   - Haz clic en "Iniciar Scraping". El Frontend llamar√° a la API y el proceso iniciar√° en la terminal del backend. Los resultados finales en formato JSON se guardar√°n autom√°ticamente en la subcarpeta `storage/datasets/default/` del scraper correspondiente.

2. **A trav√©s de la API directamente (Backend):**
   - Puedes consumir el servicio desde otros sistemas enviando un `POST` a `http://localhost:3000/api/scrape`:
     ```json
     {
       "scraper": "fotocasa",
       "url": "https://www.fotocasa.es/es/comprar/viviendas/barbate/todas-las-zonas/l"
     }
     ```
   - Puedes ver los resultados en `GET /api/results/{scraper}` (ej. `GET /api/results/fotocasa`).

## üìÅ Estructura de Resultados
Todos los scrapers exportan propiedades estructuradas en formato JSON en sus directorios locales, normalizadas con campos comunes (`Fecha reg`, `ID`, `Entidad`, `Estado`, `Tipo`, `Localidad`, `Direcci√≥n`, `Enlace a google maps`, `Ref. Catastral/registral`, `PRECIO`, `LINK ANUNCIO`).
